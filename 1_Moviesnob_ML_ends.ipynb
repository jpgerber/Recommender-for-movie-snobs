{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 Moviesnob - ML ends.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6r1R90P0okSf8IaEDi8Oa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpgerber/Recommender-for-movie-snobs/blob/master/1_Moviesnob_ML_ends.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g4fIDSNOrCP",
        "colab_type": "text"
      },
      "source": [
        "### ML approach - top and bottom on each indicator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cobVFvXOtB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "df = pd.read_csv('/content/gdrive/My Drive/moviesnob_ml_df.zip')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ntg83zIWZez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUu22chFPFFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "6cc7926b-ed7b-4cb5-fff9-dd6a499f21a2"
      },
      "source": [
        "! pip install surprise\n",
        "from surprise import Dataset, Reader, accuracy, SVDpp, SVD\n",
        "from surprise.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting surprise\n",
            "  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/da/b5700d96495fb4f092be497f02492768a3d96a3f4fa2ae7dea46d4081cfa/scikit-surprise-1.1.0.tar.gz (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.12.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.0-cp36-cp36m-linux_x86_64.whl size=1675734 sha256=dfbcac883a02120dbd3bfd9e9629a343434f87d27e88481350b7937cf24f4001\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/fa/8c/16c93fccce688ae1bde7d979ff102f7bee980d9cfeb8641bcf\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.0 surprise-0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>canonical</th>\n",
              "      <th>newold_r</th>\n",
              "      <th>statler_waldorf</th>\n",
              "      <th>obscurist</th>\n",
              "      <th>contrariness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>307</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.43949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.019481</td>\n",
              "      <td>0.573882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>481</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.43949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.019481</td>\n",
              "      <td>0.573882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1091</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.43949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.019481</td>\n",
              "      <td>0.573882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1257</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.43949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.019481</td>\n",
              "      <td>0.573882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1449</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.43949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.019481</td>\n",
              "      <td>0.573882</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  ...  statler_waldorf  obscurist  contrariness\n",
              "0       1      307     3.5  ...              0.0  -0.019481      0.573882\n",
              "1       1      481     3.5  ...              0.0  -0.019481      0.573882\n",
              "2       1     1091     1.5  ...              0.0  -0.019481      0.573882\n",
              "3       1     1257     4.5  ...              0.0  -0.019481      0.573882\n",
              "4       1     1449     4.5  ...              0.0  -0.019481      0.573882\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZXPbtDYPceM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e50f499b-41e1-44a7-e414-8096f6b95422"
      },
      "source": [
        "# First filter the dataset because extreme values reflect infrequent raters\n",
        "\n",
        "# Filtering out the extremes here\n",
        "new_old_filter = df.newold_r.isin([-1,1])\n",
        "statler_waldorf_filter = df.statler_waldorf == 1\n",
        "obscurist_filter = df.obscurist.isin([-1,1])\n",
        "contrariness_filter = df.contrariness > 2.5\n",
        "\n",
        "filter = new_old_filter | statler_waldorf_filter | obscurist_filter | contrariness_filter\n",
        "df = df[filter == 0]\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27681984, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>canonical</th>\n",
              "      <th>newold_r</th>\n",
              "      <th>statler_waldorf</th>\n",
              "      <th>obscurist</th>\n",
              "      <th>contrariness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>307</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.43949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.019481</td>\n",
              "      <td>0.573882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>481</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.43949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.019481</td>\n",
              "      <td>0.573882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1091</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.43949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.019481</td>\n",
              "      <td>0.573882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1257</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.43949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.019481</td>\n",
              "      <td>0.573882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1449</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.43949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.019481</td>\n",
              "      <td>0.573882</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  ...  statler_waldorf  obscurist  contrariness\n",
              "0       1      307     3.5  ...              0.0  -0.019481      0.573882\n",
              "1       1      481     3.5  ...              0.0  -0.019481      0.573882\n",
              "2       1     1091     1.5  ...              0.0  -0.019481      0.573882\n",
              "3       1     1257     4.5  ...              0.0  -0.019481      0.573882\n",
              "4       1     1449     4.5  ...              0.0  -0.019481      0.573882\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3DaanD6ROM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9bb4c0d0-d5b2-446d-d602-bf9420288540"
      },
      "source": [
        "# Load the movielens-100k dataset (download it if needed),\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "# sample random trainset and testset\n",
        "# test set is made of 25% of the ratings.\n",
        "trainset, testset = train_test_split(data, test_size=.25)\n",
        "\n",
        "# We'll use the famous SVD algorithm.\n",
        "algo = SVDpp()\n",
        "\n",
        "# Train the algorithm on the trainset, and predict ratings for the testset\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Then compute RMSE\n",
        "print(accuracy.rmse(predictions))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
            "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "RMSE: 0.9246\n",
            "0.9245871858367066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0aI7mtbRu0N",
        "colab_type": "text"
      },
      "source": [
        "### Doing the indicator tuning (first version)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrdco_ACRgJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = pd.DataFrame(columns=['indicator','RMSE_uppersplit','RMSE_lowersplit'])\n",
        "#results.set_index([pd.Index(['statler_waldorf','newold_r','obscurist','contrariness'])])\n",
        "saved_params = pd.DataFrame(columns=['indicator','n_factors','n_epochs','lr_all','reg_all'])\n",
        "fitted_rmse = []"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uycYe2JXSHra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd108b9c-5cb1-495b-e810-912e1838e6c5"
      },
      "source": [
        "# This cell is my machine learning part\n",
        "\n",
        "sort_key = ['statler_waldorf','newold_r','obscurist','contrariness']\n",
        "for item in sort_key:\n",
        "    # Set up parameter grid\n",
        "    param_grid = {'n_factors':[50,100,150],'n_epochs':[20,30],  'lr_all':[0.005,0.01],'reg_all':[0.02,0.1]}\n",
        "    print('Making rating samples')\n",
        "    # Set up the raw samples\n",
        "    df = df.sort_values(by=item, ascending=False)\n",
        "    ratings_upper = df.iloc[0:100000,:]\n",
        "    ratings_lower = df.iloc[-100000:,:]\n",
        "    reader = Reader(rating_scale=(1, 5)) # Make a reader\n",
        "    # Now for the upper half (load reader)\n",
        "    data = Dataset.load_from_df(ratings_upper[['userId', 'movieId', 'rating']], reader)\n",
        "    raw_ratings = data.raw_ratings #get raw ratings\n",
        "    random.shuffle(raw_ratings) # shuffle\n",
        "    threshold = int(.75 * len(raw_ratings))\n",
        "    A_raw_ratings = raw_ratings[:threshold]\n",
        "    B_raw_ratings = raw_ratings[threshold:] #split into two samples\n",
        "    data.raw_ratings = A_raw_ratings #keep sample A in reader\n",
        "    print('Loaded data, now grid search...')\n",
        "    gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5) # instantiate the model\n",
        "    print('Training on {} upper'.format(item))\n",
        "    gs.fit(data) #fit it!\n",
        "    params = gs.best_params['rmse'] #get best params\n",
        "    saved_params = saved_params.append(params, ignore_index=True) #append to df\n",
        "    print(saved_params.head())\n",
        "    print('Saved parameters for upper {}'.format(item))\n",
        "    tuned_algo = gs.best_estimator['rmse'] #get tuned version\n",
        "    trainset = data.build_full_trainset() #surprise requires the full trainset\n",
        "    testset = data.construct_testset(B_raw_ratings)  # testset is now the set B\n",
        "    predictions = algo.test(testset) #make predictions\n",
        "    rmse_uppersplit = accuracy.rmse(predictions, verbose=False) #get accuracy score\n",
        "    print('Unbiased accuracy is {}'.format(rmse_uppersplit))\n",
        "    fitted_rmse.append(rmse_uppersplit) # add that to my results list\n",
        "    print(fitted_rmse)\n",
        "    \n",
        "    ## Start the other half\n",
        "    data = Dataset.load_from_df(ratings_lower[['userId', 'movieId', 'rating']], reader)\n",
        "    raw_ratings = data.raw_ratings\n",
        "    random.shuffle(raw_ratings)\n",
        "    threshold = int(.75 * len(raw_ratings))\n",
        "    A_raw_ratings = raw_ratings[:threshold]\n",
        "    B_raw_ratings = raw_ratings[threshold:]\n",
        "    data.raw_ratings = A_raw_ratings\n",
        "    print('Loaded data, now grid search...')\n",
        "    gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5)\n",
        "    print('Training on {} lower'.format(item))\n",
        "    gs.fit(data)\n",
        "    params = gs.best_params['rmse']\n",
        "    saved_params = saved_params.append(params, ignore_index=True)\n",
        "    print(saved_params.head())\n",
        "    print('Saved parameters for lower {}'.format(item))\n",
        "    tuned_algo = gs.best_estimator['rmse']\n",
        "    trainset = data.build_full_trainset()\n",
        "    testset = data.construct_testset(B_raw_ratings)  # testset is now the set B\n",
        "    predictions = algo.test(testset)\n",
        "    rmse_lowersplit = accuracy.rmse(predictions, verbose=False)\n",
        "    print('Unbiased accuracy is {}'.format(rmse_lowersplit))\n",
        "    fitted_rmse.append(rmse_lowersplit)\n",
        "    print(fitted_rmse)\n",
        "    new_row = pd.DataFrame({\"RMSE_uppersplit\":rmse_uppersplit, \"RMSE_lowersplit\":rmse_lowersplit}, index=[item])\n",
        "    results = results.append(new_row)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Making rating samples\n",
            "Loaded data, now grid search...\n",
            "Training on statler_waldorf upper\n",
            "   indicator  n_factors  n_epochs  lr_all  reg_all\n",
            "0        NaN       50.0      30.0    0.01      0.1\n",
            "Saved parameters for upper statler_waldorf\n",
            "Unbiased accuracy is 1.7094967016054754\n",
            "[1.7094967016054754]\n",
            "Loaded data, now grid search...\n",
            "Training on statler_waldorf lower\n",
            "   indicator  n_factors  n_epochs  lr_all  reg_all\n",
            "0        NaN       50.0      30.0   0.010      0.1\n",
            "1        NaN       50.0      30.0   0.005      0.1\n",
            "Saved parameters for lower statler_waldorf\n",
            "Unbiased accuracy is 0.711035355520385\n",
            "[1.7094967016054754, 0.711035355520385]\n",
            "Making rating samples\n",
            "Loaded data, now grid search...\n",
            "Training on newold_r upper\n",
            "   indicator  n_factors  n_epochs  lr_all  reg_all\n",
            "0        NaN       50.0      30.0   0.010      0.1\n",
            "1        NaN       50.0      30.0   0.005      0.1\n",
            "2        NaN       50.0      30.0   0.010      0.1\n",
            "Saved parameters for upper newold_r\n",
            "Unbiased accuracy is 1.2619136591700717\n",
            "[1.7094967016054754, 0.711035355520385, 1.2619136591700717]\n",
            "Loaded data, now grid search...\n",
            "Training on newold_r lower\n",
            "   indicator  n_factors  n_epochs  lr_all  reg_all\n",
            "0        NaN       50.0      30.0   0.010      0.1\n",
            "1        NaN       50.0      30.0   0.005      0.1\n",
            "2        NaN       50.0      30.0   0.010      0.1\n",
            "3        NaN       50.0      30.0   0.010      0.1\n",
            "Saved parameters for lower newold_r\n",
            "Unbiased accuracy is 1.1497379228328515\n",
            "[1.7094967016054754, 0.711035355520385, 1.2619136591700717, 1.1497379228328515]\n",
            "Making rating samples\n",
            "Loaded data, now grid search...\n",
            "Training on obscurist upper\n",
            "   indicator  n_factors  n_epochs  lr_all  reg_all\n",
            "0        NaN       50.0      30.0   0.010      0.1\n",
            "1        NaN       50.0      30.0   0.005      0.1\n",
            "2        NaN       50.0      30.0   0.010      0.1\n",
            "3        NaN       50.0      30.0   0.010      0.1\n",
            "4        NaN       50.0      30.0   0.010      0.1\n",
            "Saved parameters for upper obscurist\n",
            "Unbiased accuracy is 1.1491441065419081\n",
            "[1.7094967016054754, 0.711035355520385, 1.2619136591700717, 1.1497379228328515, 1.1491441065419081]\n",
            "Loaded data, now grid search...\n",
            "Training on obscurist lower\n",
            "   indicator  n_factors  n_epochs  lr_all  reg_all\n",
            "0        NaN       50.0      30.0   0.010      0.1\n",
            "1        NaN       50.0      30.0   0.005      0.1\n",
            "2        NaN       50.0      30.0   0.010      0.1\n",
            "3        NaN       50.0      30.0   0.010      0.1\n",
            "4        NaN       50.0      30.0   0.010      0.1\n",
            "Saved parameters for lower obscurist\n",
            "Unbiased accuracy is 1.2305141566028406\n",
            "[1.7094967016054754, 0.711035355520385, 1.2619136591700717, 1.1497379228328515, 1.1491441065419081, 1.2305141566028406]\n",
            "Making rating samples\n",
            "Loaded data, now grid search...\n",
            "Training on contrariness upper\n",
            "   indicator  n_factors  n_epochs  lr_all  reg_all\n",
            "0        NaN       50.0      30.0   0.010      0.1\n",
            "1        NaN       50.0      30.0   0.005      0.1\n",
            "2        NaN       50.0      30.0   0.010      0.1\n",
            "3        NaN       50.0      30.0   0.010      0.1\n",
            "4        NaN       50.0      30.0   0.010      0.1\n",
            "Saved parameters for upper contrariness\n",
            "Unbiased accuracy is 2.363875126312725\n",
            "[1.7094967016054754, 0.711035355520385, 1.2619136591700717, 1.1497379228328515, 1.1491441065419081, 1.2305141566028406, 2.363875126312725]\n",
            "Loaded data, now grid search...\n",
            "Training on contrariness lower\n",
            "   indicator  n_factors  n_epochs  lr_all  reg_all\n",
            "0        NaN       50.0      30.0   0.010      0.1\n",
            "1        NaN       50.0      30.0   0.005      0.1\n",
            "2        NaN       50.0      30.0   0.010      0.1\n",
            "3        NaN       50.0      30.0   0.010      0.1\n",
            "4        NaN       50.0      30.0   0.010      0.1\n",
            "Saved parameters for lower contrariness\n",
            "Unbiased accuracy is 0.5489919591396581\n",
            "[1.7094967016054754, 0.711035355520385, 1.2619136591700717, 1.1497379228328515, 1.1491441065419081, 1.2305141566028406, 2.363875126312725, 0.5489919591396581]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vQIzzxFRyvs",
        "colab_type": "text"
      },
      "source": [
        "### Now for turicreate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb59_hegR0tA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the factorizer model and add the features one by one\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}