{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0 Movie Snob - Data Clean & Wrangle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8NmQPT2ZcRCaUYs+BKbht",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpgerber/Recommender-for-movie-snobs/blob/master/0_Movie_Snob_Data_Clean_%26_Wrangle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De4K4_JTy55Y",
        "colab_type": "text"
      },
      "source": [
        "# This notebook cleans and combines the MovieLens data with a canonical movie list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHeXVgjNB6Jt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import zipfile, io\n",
        "\n",
        "# Make the canonical list\n",
        "# Importing the 1,001 list and converting it to a list\n",
        "snob_url = 'https://1001films.fandom.com/wiki/The_List'\n",
        "snob_text= requests.get(snob_url)\n",
        "soup = BeautifulSoup(snob_text.content, 'html.parser')\n",
        "basic_list = (soup.body.find_all('b'))\n",
        "thousand_list = [item.text for item in basic_list]\n",
        "thousandone_movies = pd.DataFrame(thousand_list, columns = ['title']).drop(0) # Convert to df\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm15s-2LxVr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the MovieLens dataset\n",
        "# Importing the ratings data\n",
        "list_of_urls = ['http://files.grouplens.org/datasets/movielens/ml-latest.zip'] # I originally checked several files\n",
        "for url in list_of_urls:\n",
        "    ratings_small_file = requests.get(url)\n",
        "    z = zipfile.ZipFile(io.BytesIO(ratings_small_file.content))\n",
        "    z.extractall()\n",
        "\n",
        "gl_movies = pd.read_csv('ml-latest/movies.csv', sep = ',', header = 0) # Make the df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRcLEUWLzSs_",
        "colab_type": "text"
      },
      "source": [
        "##### There will be lots of different types of cleaning.\n",
        "First, extract the year of release from the string titles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxaoRko0x2yP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create columns of movie years in each database\n",
        "# Make sure the titles don't have trailing spaces\n",
        "thousandone_movies['title'] = thousandone_movies['title'].str.rstrip()\n",
        "gl_movies['title'] = gl_movies['title'].str.rstrip()\n",
        "# Then take the slices (the years are in parantheses at the end of the title)\n",
        "thousandone_movies['year'] = [title[slice(-5,-1)] for title in thousandone_movies['title']]\n",
        "gl_movies['year'] = [title[slice(-5,-1)] for title in gl_movies['title']]\n",
        "\n",
        "# Then convert these strings to numbers (there is one title missing a year!)\n",
        "# Define a conversion function\n",
        "def ConvertYear(value):\n",
        "    '''This function converts integer strings to integers and non-integer strings to zero'''\n",
        "    try:\n",
        "        return int(value)\n",
        "    except: \n",
        "        return 0\n",
        "# Then apply it to the columns for both thousandone_movies and ed_choices\n",
        "thousandone_movies['year'] = thousandone_movies['year'].apply(lambda year: ConvertYear(\n",
        "    year))\n",
        "gl_movies['year'] = gl_movies['year'].apply(lambda year: ConvertYear(year))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgo3UUMUy8lX",
        "colab_type": "text"
      },
      "source": [
        "Then make a custom function to test three years at a time and return the best string match."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbKbafa3x536",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fuzzywuzzy \n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process\n",
        "# Specify the matching function (we only need one of the outputs)\n",
        "def Matcher(title, choices):\n",
        "    title_match, percent_match, match3 = process.extractOne(title, choices)\n",
        "    return title_match\n",
        "# And here's a function for using the tokenizer\n",
        "def Matcher_token(title, choices):\n",
        "    title_match, percent_match, match3 = process.extractOne(title, choices, \n",
        "                                                            scorer=fuzz.token_sort_ratio)\n",
        "    return title_match\n",
        "\n",
        "#Define a filter to return targets for +/-1 year only\n",
        "def YearFilter (year):\n",
        "    years = [year-1, year, year+1]\n",
        "    return gl_movies[gl_movies.year.isin(years)].title\n",
        "\n",
        "# Running the tokenizer over the filtered target set\n",
        "for index, row in thousandone_movies.iterrows():\n",
        "    # call the filter\n",
        "    targets = YearFilter(row.year)\n",
        "    # update the new cell work out the matcher\n",
        "    thousandone_movies.loc[index,'return_match'] = Matcher_token(row.title, targets)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFS7OuiiB7yL",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The following movies were misidentified and so needed re-coding\n",
        "Intolerance (1916) - 7243\n",
        "Broken Blossoms (1919) - 6988\n",
        "Häxan (1923) - 25744\n",
        "Sunrise (1927) - 8125\n",
        "The Unknown (1927) - 25762\n",
        "A Throw of Dice (Prapancha Pash) (1929) - NONE\n",
        "Tabu (1931) - 5599\n",
        "The Vampire (Vampyr) (1932) - 25793\n",
        "Scarface: The Shame of a Nation (1932) - 25788\n",
        "Midnight Song (Ye Ban Ge Sheng) (1937) - None\n",
        "Henry V (1944) - 25901\n",
        "The Battle of San Pietro (1945) - 80104\n",
        "Gun Crazy (1949) - 8751\n",
        "Sunset Blvd. (1950) - 922\n",
        "Europa '51 (1952) - 25966\n",
        "Tokyo Story (1953) - 6643\n",
        "The Wanton Countess (Senso) (1954) - 69911\n",
        "The Sins of Lola Montes (Lola Montès) (1955) - 8143\n",
        "Pather Panchali (1955) - 668\n",
        "Ordet (1955) - 6981\n",
        "Hill 24 Doesn't Answer (1955) - NONE\n",
        "Dracula (1958) - 5649\n",
        "Dog Star Man - 137579\t137581\t137583\t137585\t137587\n",
        "Blonde Cobra (1963) - None\n",
        "Playtime (1967) - 26171\n",
        "Week End (1967) - 7749\n",
        "Viy (1967) - 97065\n",
        "Andrei Rublev (Andrei Rublyov) (1966) - 26150\n",
        "A Touch of Zen (Hsia Nu) (1969) - 32511\n",
        "M*A*S*H (1970) - 5060\n",
        "The Sorrow and the Pity (La Chagrin et la Pitié) (1971) - 32853\n",
        "Ceddo (1977) - 71973\n",
        "Up in Smoke (1978) - 1194\n",
        "Raiders of the Lost Ark (1981) - 1198\n",
        "Yol (1982) - 6151\n",
        "Koyaanisqatsi (1983) - 1289\n",
        "The Naked Gun (1988) - 3868\n",
        "Henry: Portrait of a Serial Killer (1990) - 2159\n",
        "The Actress (Yuen Ling-Yuk) (1992) - 114394\n",
        "Hana-Bi (1997) - 1809\n",
        "Buffalo '66 (1998) - 1916\n",
        "Tetsuo (1989) - 4552\n",
        "A One and a Two (Yi Yi) (2000) - 4334\n",
        "Y Tu Mama Tambien (2001) - 5225\n",
        "Oldboy (2003) - 107314\n",
        "Paranormal Activity (2007) - 71379\n",
        "Precious: Based on the Novel \"Push\" by Sapphire (2009) - 72395\n",
        "The Favourite (2018) - 183837\n",
        "Vice (2018) - 127323"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dmNIWGz0lMP",
        "colab_type": "text"
      },
      "source": [
        "Join the canonical list to the ratings list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW9z6wOgqrd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the indicator variable to the canonical list.\n",
        "thousandone_movies['canonical'] = 1\n",
        "#print(thousandone_movies.head())\n",
        "\n",
        "# Add the canonical indicator to the movie file, drop the irrelevant columns \n",
        "#and fill the missing values with zeroes\n",
        "gl_movies = pd.merge(gl_movies, thousandone_movies, left_on='title', right_on='return_match', how='outer', \n",
        "         suffixes=('', '_canon')).drop(['year_canon', \n",
        "                                        'return_match', 'title_canon'], axis=1).fillna({'canonical':0})\n",
        "\n",
        "print(gl_movies.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dezz4x4wsxYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now add the mismatched ones\n",
        "\n",
        "handcode_ids = [7243, 6988, 25744, 8125, 25762, 5599, 25793, 25788, 25901, 80104,\n",
        "                         8751, 922, 25966, 6643, 69911, 8143, 668, 6981, 5649, 137579,\n",
        "                         137581, 137583, 137585, 137587, 26171, 7749, 97065, 26150, 32511,\n",
        "                         5060, 32853, 71973, 1194, 1198, 6151, 1289, 3868, 2159, 114394,\n",
        "                         1809, 1916, 4552, 4334, 5225, 107314, 71379, 72395, 183837, 127323]\n",
        "\n",
        "def handcode_row(row):\n",
        "    if row['movieId'] in handcode_ids or row['canonical'] == 1:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "gl_movies['canonical'] = gl_movies.apply(lambda row : handcode_row(row), axis=1) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wJonXP7K8aL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gl_movies.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kk23qpKOCtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gl_movies.canonical.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyQeBNwJBPhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "ratings = pd.read_csv('ml-latest/ratings.csv', sep = ',', header = 0)\n",
        "ratings['rating_date'] = ratings['timestamp'].apply(lambda x: datetime.date.fromtimestamp(x))\n",
        "\n",
        "print(ratings.head())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZOwK1PXuHzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rating2 = pd.merge(ratings, gl_movies.drop_duplicates(subset=['movieId']), how='left', on='movieId').drop(\n",
        "    ['title','genres','timestamp','year'], axis=1)  # we also dropped the long string columns and some others\n",
        "rating2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8b9fzPC04a0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Removing the one suspicious user\n",
        "rating2 = rating2[rating2.userId != 123100]\n",
        "rating2.groupby('userId').agg({'rating': 'count'}).sort_values(by='rating', ascending=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwa5oGTGPbQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyarrow.parquet as pq\n",
        "pq.write_table(table, 'example.parquet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgV9iRMVPoxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}